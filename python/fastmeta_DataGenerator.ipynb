{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import d3m utility\n",
    "from d3m import utils, index\n",
    "from d3m.container.dataset import D3MDatasetLoader, Dataset\n",
    "from d3m.metadata.pipeline import PrimitiveStep, ArgumentType\n",
    "from d3m.metadata.problem import parse_problem_description, TaskType, TaskSubtype\n",
    "from d3m.metadata import base as metadata_base\n",
    "from d3m.metadata.base import Metadata, ALL_ELEMENTS\n",
    "\n",
    "# import evaluation packages\n",
    "# remember to install it from https://gitlab.datadrivendiscovery.org/nist/nist_eval_output_validation_scoring\n",
    "# from d3m_outputs import Predictions\n",
    "\n",
    "# import python packages\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "# import networkx\n",
    "import csv\n",
    "# from importlib import reload\n",
    "\n",
    "TOP_NUM = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsbox.pipeline.fitted_pipeline import FittedPipeline\n",
    "from dsbox.template.runtime import Runtime, add_target_columns_metadata\n",
    "from dsbox.template.search import get_target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_pipeline(path) -> tuple:\n",
    "    '''\n",
    "    read a pipeline, return its rank and pipeline\n",
    "    '''\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        pipeline = json.load(f)\n",
    "        return (pipeline[\"id\"], pipeline[\"pipeline_rank\"])\n",
    "\n",
    "\n",
    "def load_for_dataset(path, res) -> list:\n",
    "    '''\n",
    "    load all the pipelines under pipeline_path and return a sorted list of them \n",
    "    '''\n",
    "\n",
    "    res_loc = os.path.join(path, res)\n",
    "    pipeline_loc = os.path.join(res_loc, \"pipelines\")\n",
    "\n",
    "    pipelines_for_dataset = os.listdir(pipeline_loc)\n",
    "    result = []\n",
    "    if pipelines_for_dataset:\n",
    "#         print(f\"Reading pipelines for {res} ...\") # are {pipelines_for_dataset} read\n",
    "#         print(\"*\" * 20)\n",
    "        for p in pipelines_for_dataset:\n",
    "            tmp_path = os.path.join(pipeline_loc, p)\n",
    "            result.append(load_one_pipeline(tmp_path))\n",
    "\n",
    "    else:\n",
    "        print(\"No fitted pipeline generated for\", res_loc)\n",
    "        return []\n",
    "    result.sort(key=lambda tup: tup[1])\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_all_fitted_pipeline(pipeline_path) -> dict:\n",
    "    '''\n",
    "    go through all the directorys from problem runs\n",
    "    '''\n",
    "\n",
    "    mypath = os.path.join(pipeline_path)\n",
    "    allfile = os.listdir(mypath)\n",
    "    pip_mapper = {}\n",
    "    for res in allfile:\n",
    "        if not res.endswith(\".txt\"):\n",
    "            pip_mapper[res] = load_for_dataset(mypath, res)\n",
    "\n",
    "    # print(allfile)\n",
    "    return pip_mapper\n",
    "\n",
    "\n",
    "def top_selection(mapper) -> dict:\n",
    "    '''\n",
    "    select top 10 pipelines from the dict of pipelines and also remove pipelines that are empty\n",
    "    '''\n",
    "    rmlist = []\n",
    "    for key in mapper.keys():\n",
    "        if len(mapper[key]) == 0:\n",
    "            rmlist.append(key)\n",
    "        if len(mapper[key]) >= TOP_NUM:\n",
    "            mapper[key] = mapper[key][0:TOP_NUM]\n",
    "    if rmlist:\n",
    "        for r in rmlist:\n",
    "            del mapper[r]\n",
    "    return mapper\n",
    "\n",
    "\n",
    "def create_fitted_pipelines_for_dataset(path, pipelines, log_dir) -> list:\n",
    "    '''\n",
    "    return a list of (fitted_pipeline, run)\n",
    "    '''\n",
    "    result = []\n",
    "    for p in pipelines:\n",
    "        result.append(FittedPipeline.load(folder_loc=path, pipeline_id=p[0], log_dir=log_dir))\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_test_dataset_for_pipeline(config_path) -> tuple:\n",
    "    '''\n",
    "    load and return test_dataset and test_problem given by configfile: test_config.json\n",
    "    '''\n",
    "    test_config_path = os.path.join(config_path, \"test_config.json\")\n",
    "    with open(test_config_path, \"r\") as f:\n",
    "        test_config = json.load(f)\n",
    "        data_path = test_config[\"dataset_schema\"]\n",
    "        problem_path = test_config[\"problem_schema\"]\n",
    "    dataset = D3MDatasetLoader()\n",
    "    if \"file:\" not in data_path:\n",
    "        data_path = 'file://{dataset_path}'.format(dataset_path=os.path.abspath(data_path))\n",
    "    with open(problem_path) as f:\n",
    "        problem_doc = json.load(f)\n",
    "        problem = Metadata(problem_doc)\n",
    "    dataset = dataset.load(dataset_uri=data_path)\n",
    "    dataset = add_target_columns_metadata(dataset, problem)\n",
    "    return dataset, problem\n",
    "\n",
    "\n",
    "def predict_and_write(pipeline, test_dataset, test_problem, saving_path) -> str:\n",
    "    '''\n",
    "    run produce for pipelines and store as .csvs and return stored path\n",
    "    '''\n",
    "    resID = test_problem.query(())[\"inputs\"][\"data\"][0][\"targets\"][0][\"resID\"]\n",
    "    test_length = test_dataset.metadata.query((resID, ALL_ELEMENTS))[\"dimension\"][\"length\"]\n",
    "    for v in range(0, test_length):\n",
    "        types = test_dataset.metadata.query((resID, ALL_ELEMENTS, v))[\"semantic_types\"]\n",
    "        for t in types:\n",
    "            if t == \"https://metadata.datadrivendiscovery.org/types/TrueTarget\":\n",
    "                target_col_name = test_dataset.metadata.query((resID, ALL_ELEMENTS, v))[\"name\"]\n",
    "                break\n",
    "\n",
    "    pipeline.produce(inputs=[test_dataset])\n",
    "    prediction = pipeline.runtime.produce_outputs[-1]\n",
    "    d3m_index = get_target_columns(test_dataset, test_problem)[\"d3mIndex\"]\n",
    "    d3m_index = d3m_index.reset_index().drop(columns=[\"index\"])\n",
    "    prediction_col_name = prediction.columns[-1]\n",
    "    prediction[\"d3mIndex\"] = d3m_index\n",
    "    prediction = prediction[[\"d3mIndex\", prediction_col_name]]\n",
    "    prediction = prediction.rename(columns={prediction_col_name: target_col_name})\n",
    "    # print(prediction.head())\n",
    "    with open(saving_path, \"w\") as f:\n",
    "        prediction.to_csv(f, index=False)\n",
    "    print(\"Prediction result wrote to\", saving_path)\n",
    "    return saving_path\n",
    "\n",
    "\n",
    "def score_prediction(prediction_file, ground_truth_dir) -> dict:\n",
    "    '''\n",
    "    using NIST to score the result and return a dict that contain informations\n",
    "    '''\n",
    "    res = {}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_loc = \"/nfs1/dsbox-repo/runs/wade-run/ll0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pipelines for LL0_285_flags ...\n",
      "********************\n",
      "Reading pipelines for LL0_747_servo ...\n",
      "********************\n",
      "Reading pipelines for LL0_814_chscase_vine2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_853_housing ...\n",
      "********************\n",
      "Reading pipelines for LL0_475_analcatdata_germangss ...\n",
      "********************\n",
      "Reading pipelines for LL0_40474_thyroid_allbp ...\n",
      "********************\n",
      "Reading pipelines for LL0_uci_dow_jones_index ...\n",
      "********************\n",
      "Reading pipelines for LL0_1497_wall_robot_navigation ...\n",
      "********************\n",
      "Reading pipelines for LL0_1569_poker_hand ...\n",
      "********************\n",
      "Reading pipelines for LL0_1054_mc2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1510_wdbc ...\n",
      "********************\n",
      "Reading pipelines for LL0_1219_click_prediction_small ...\n",
      "********************\n",
      "Reading pipelines for LL0_434_benzo32 ...\n",
      "********************\n",
      "Reading pipelines for LL0_801_chscase_funds ...\n",
      "********************\n",
      "Reading pipelines for LL0_231_hungarian ...\n",
      "********************\n",
      "Reading pipelines for LL0_23_cmc ...\n",
      "********************\n",
      "Reading pipelines for LL0_1115_teachingAssistant ...\n",
      "********************\n",
      "Reading pipelines for LL0_40649_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001 ...\n",
      "********************\n",
      "Reading pipelines for LL0_522_pm10 ...\n",
      "********************\n",
      "Reading pipelines for LL0_40669_corral ...\n",
      "********************\n",
      "Reading pipelines for LL0_1220_click_prediction_small ...\n",
      "********************\n",
      "Reading pipelines for LL0_679_rmftsa_sleepdata ...\n",
      "********************\n",
      "Reading pipelines for LL0_555_analcatdata_apnea3 ...\n",
      "********************\n",
      "Reading pipelines for LL0_452_analcatdata_broadwaymult ...\n",
      "********************\n",
      "Reading pipelines for LL0_709_disclosure_x_bias ...\n",
      "********************\n",
      "Reading pipelines for LL0_1044_eye_movements ...\n",
      "********************\n",
      "Reading pipelines for LL0_953_splice ...\n",
      "********************\n",
      "Reading pipelines for LL0_1524_vertebra_column ...\n",
      "********************\n",
      "Reading pipelines for LL0_4134_bioresponse ...\n",
      "********************\n",
      "Reading pipelines for LL0_574_house_16h ...\n",
      "********************\n",
      "Reading pipelines for LL0_4340_engine1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_560_bodyfat ...\n",
      "********************\n",
      "Reading pipelines for LL0_300_isolet ...\n",
      "********************\n",
      "Reading pipelines for LL0_195_auto_price ...\n",
      "********************\n",
      "Reading pipelines for LL0_40680_mofn_3_7_10 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1176_internet_advertisements ...\n",
      "********************\n",
      "Reading pipelines for LL0_488_colleges_aaup ...\n",
      "********************\n",
      "Reading pipelines for LL0_1446_CostaMadre1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1050_pc3 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1068_pc1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1525_wall_robot_navigation ...\n",
      "********************\n",
      "Reading pipelines for LL0_512_balloon ...\n",
      "********************\n",
      "Reading pipelines for LL0_56_vote ...\n",
      "********************\n",
      "Reading pipelines for LL0_40677_led24 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1040_sylva_prior ...\n",
      "********************\n",
      "Reading pipelines for LL0_188_eucalyptus ...\n",
      "********************\n",
      "Reading pipelines for LL0_312_scene ...\n",
      "********************\n",
      "Reading pipelines for LL0_11_balance_scale ...\n",
      "********************\n",
      "Reading pipelines for LL0_694_diggle_table_a2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1442_MegaWatt1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1063_kc2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_200_pbc ...\n",
      "********************\n",
      "Reading pipelines for LL0_1471_eeg_eye_state ...\n",
      "********************\n",
      "Reading pipelines for LL0_531_boston ...\n",
      "********************\n",
      "Reading pipelines for LL0_40687_solar_flare_2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_463_backache ...\n",
      "********************\n",
      "Reading pipelines for LL0_12_mfeat_factors ...\n",
      "********************\n",
      "Reading pipelines for LL0_23395_comet_mc_sample ...\n",
      "********************\n",
      "Reading pipelines for LL0_1459_artificial_characters ...\n",
      "********************\n",
      "Reading pipelines for LL0_455_cars ...\n",
      "********************\n",
      "Reading pipelines for LL0_43_haberman ...\n",
      "********************\n",
      "Reading pipelines for LL0_1571_fourclass_scale ...\n",
      "********************\n",
      "Reading pipelines for LL0_1507_twonorm ...\n",
      "********************\n",
      "Reading pipelines for LL0_3_kr_vs_kp ...\n",
      "********************\n",
      "Reading pipelines for LL0_664_chscase_census6 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1038_gina_agnostic ...\n",
      "********************\n",
      "Reading pipelines for LL0_968_analcatdata_birthday ...\n",
      "********************\n",
      "Reading pipelines for LL0_198_delta_elevators ...\n",
      "********************\n",
      "Reading pipelines for LL0_1245_lungcancer_shedden ...\n",
      "********************\n",
      "Reading pipelines for LL0_536_arsenic_male_lung ...\n",
      "********************\n",
      "Reading pipelines for LL0_573_cpu_act ...\n",
      "********************\n",
      "Reading pipelines for LL0_550_quake ...\n",
      "********************\n",
      "Reading pipelines for LL0_40475_thyroid_allhyper ...\n",
      "********************\n",
      "Reading pipelines for LL0_201_pol ...\n",
      "********************\n",
      "Reading pipelines for LL0_37_diabetes ...\n",
      "********************\n",
      "Reading pipelines for LL0_500_analcatdata_vineyard ...\n",
      "********************\n",
      "Reading pipelines for LL0_811_rmftsa_ctoarrivals ...\n",
      "********************\n",
      "Reading pipelines for LL0_1468_cnae_9 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1028_swd ...\n",
      "********************\n",
      "Reading pipelines for LL0_1043_ada_agnostic ...\n",
      "********************\n",
      "Reading pipelines for LL0_1552_autouniv_au7_1100 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1500_seismic_bumps ...\n",
      "********************\n",
      "Reading pipelines for LL0_1555_autoUniv_au6_1000 ...\n",
      "********************\n",
      "Reading pipelines for LL0_40648_GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_733_machine_cpu ...\n",
      "********************\n",
      "Reading pipelines for LL0_1480_ilpd ...\n",
      "********************\n",
      "Reading pipelines for LL0_59_ionosphere ...\n",
      "********************\n",
      "Reading pipelines for LL0_1530_volcanoes_a4 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1113_kddcup99 ...\n",
      "********************\n",
      "Reading pipelines for LL0_676_disclosure_x_tampered ...\n",
      "********************\n",
      "Reading pipelines for LL0_197_cpu_act ...\n",
      "********************\n",
      "Reading pipelines for LL0_40647_GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1451_piechart1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1447_castmetal1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_494_analcatdata_hiroshima ...\n",
      "********************\n",
      "Reading pipelines for LL0_1506_thoracic_surgery ...\n",
      "********************\n",
      "Reading pipelines for LL0_377_synthetic_control ...\n",
      "********************\n",
      "Reading pipelines for LL0_1527_volcanoes_a1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_6332_cylinder_bands ...\n",
      "********************\n",
      "Reading pipelines for LL0_549_strikes ...\n",
      "********************\n",
      "Reading pipelines for LL0_308_puma32h ...\n",
      "********************\n",
      "Reading pipelines for LL0_333_monks_problems_1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1570_wilt ...\n",
      "********************\n",
      "Reading pipelines for LL0_40_sonar ...\n",
      "********************\n",
      "Reading pipelines for LL0_1037_ada_prior ...\n",
      "********************\n",
      "Reading pipelines for LL0_1100_popularkids ...\n",
      "********************\n",
      "Reading pipelines for LL0_344_mv ...\n",
      "********************\n",
      "Reading pipelines for LL0_255_breast_cancer_wisconsin_original ...\n",
      "********************\n",
      "Reading pipelines for LL0_40712_crx ...\n",
      "********************\n",
      "Reading pipelines for LL0_1528_volcanoes_a2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1558_bank_marketing ...\n",
      "********************\n",
      "Reading pipelines for LL0_39_ecoli ...\n",
      "********************\n",
      "Reading pipelines for LL0_40497_thyroid_ann ...\n",
      "********************\n",
      "Reading pipelines for LL0_558_bank32nh ...\n",
      "********************\n",
      "Reading pipelines for LL0_1479_hill_valley ...\n",
      "********************\n",
      "Reading pipelines for LL0_36_segment ...\n",
      "********************\n",
      "Reading pipelines for LL0_1487_ozone_level_8hr ...\n",
      "********************\n",
      "Reading pipelines for LL0_712_chscase_geyser1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_854_fishcatch ...\n",
      "********************\n",
      "Reading pipelines for LL0_481_biomed ...\n",
      "********************\n",
      "Reading pipelines for LL0_1457_amazon_commerce_reviews ...\n",
      "********************\n",
      "Reading pipelines for LL0_50_tic_tac_toe ...\n",
      "********************\n",
      "Reading pipelines for LL0_223_stock ...\n",
      "********************\n",
      "Reading pipelines for LL0_1498_sa_heart ...\n",
      "********************\n",
      "Reading pipelines for LL0_840_autoHorse ...\n",
      "********************\n",
      "Reading pipelines for LL0_329_hayes_roth ...\n",
      "********************\n",
      "Reading pipelines for LL0_301_ozone_level ...\n",
      "********************\n",
      "Reading pipelines for LL0_uci_forest_fires ...\n",
      "********************\n",
      "Reading pipelines for LL0_8_liver_disorders ...\n",
      "********************\n",
      "Reading pipelines for LL0_40663_calendarDOW ...\n",
      "********************\n",
      "Reading pipelines for LL0_565_water_treatment ...\n",
      "********************\n",
      "Reading pipelines for LL0_23397_comet_mc_sample ...\n",
      "********************\n",
      "Reading pipelines for LL0_1494_qsar_biodeg ...\n",
      "********************\n",
      "Reading pipelines for LL0_1490_planning_relax ...\n",
      "********************\n",
      "Reading pipelines for LL0_1511_wholesale_customers ...\n",
      "********************\n",
      "Reading pipelines for LL0_949_arsenic_female_bladder ...\n",
      "********************\n",
      "Reading pipelines for LL0_721_pwLinear ...\n",
      "********************\n",
      "Reading pipelines for LL0_1531_volcanoes_b1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_216_elevators ...\n",
      "********************\n",
      "Reading pipelines for LL0_1027_esl ...\n",
      "********************\n",
      "Reading pipelines for LL0_298_coil2000 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1049_pc4 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1470_dresses_sales ...\n",
      "********************\n",
      "Reading pipelines for LL0_1489_phoneme ...\n",
      "********************\n",
      "Reading pipelines for LL0_1508_user_knowledge ...\n",
      "********************\n",
      "Reading pipelines for LL0_40705_tokyo1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1008_analcatdata_reviewer ...\n",
      "********************\n",
      "Reading pipelines for LL0_503_wind ...\n",
      "********************\n",
      "Reading pipelines for LL0_1460_banana ...\n",
      "********************\n",
      "Reading pipelines for LL0_1466_cardiotocography ...\n",
      "********************\n",
      "Reading pipelines for LL0_191_wisconsin ...\n",
      "********************\n",
      "Reading pipelines for LL0_44_spambase ...\n",
      "********************\n",
      "Reading pipelines for LL0_1475_first_order_theorem_proving ...\n",
      "********************\n",
      "Reading pipelines for LL0_1538_volcanoes_d1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_511_plasma_retinol ...\n",
      "********************\n",
      "Reading pipelines for LL0_307_vowel ...\n",
      "********************\n",
      "Reading pipelines for LL0_504_analcatdata_supreme ...\n",
      "********************\n",
      "Reading pipelines for LL0_1121_badges2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1030_era ...\n",
      "********************\n",
      "Reading pipelines for LL0_22_mfeat_zernike ...\n",
      "********************\n",
      "Reading pipelines for LL0_1036_sylva_agnostic ...\n",
      "********************\n",
      "Reading pipelines for LL0_186_braziltourism ...\n",
      "********************\n",
      "Reading pipelines for LL0_4541_diabetes130us ...\n",
      "********************\n",
      "Reading pipelines for LL0_852_analcatdata_gsssexsurvey ...\n",
      "********************\n",
      "Reading pipelines for LL0_40499_texture ...\n",
      "********************\n",
      "Reading pipelines for LL0_1534_volcanoes_b4 ...\n",
      "********************\n",
      "Reading pipelines for LL0_204_cholesterol ...\n",
      "********************\n",
      "Reading pipelines for LL0_31_credit_g ...\n",
      "********************\n",
      "Reading pipelines for LL0_40646_GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1499_seeds ...\n",
      "********************\n",
      "Reading pipelines for LL0_1553_autoUniv_au7_700 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1067_kc1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1053_jm1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_40706_parity5_plus_5 ...\n",
      "********************\n",
      "Reading pipelines for LL0_509_places ...\n",
      "********************\n",
      "Reading pipelines for LL0_703_chscase_foot ...\n",
      "********************\n",
      "Reading pipelines for LL0_1504_steel_plates_fault ...\n",
      "********************\n",
      "Reading pipelines for LL0_458_analcatdata_authorship ...\n",
      "********************\n",
      "Reading pipelines for LL0_1501_semeion ...\n",
      "********************\n",
      "Reading pipelines for LL0_1467_climate_model_simulation_crashes ...\n",
      "********************\n",
      "Reading pipelines for LL0_40704_titanic ...\n",
      "********************\n",
      "Reading pipelines for LL0_1548_autouniv_au4_2500 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1481_kr_vs_k ...\n",
      "********************\n",
      "Reading pipelines for LL0_40686_solar_flare_1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1488_parkinsons ...\n",
      "********************\n",
      "Reading pipelines for LL0_180_covertype ...\n",
      "********************\n",
      "Reading pipelines for LL0_25_colic ...\n",
      "********************\n",
      "Reading pipelines for LL0_1462_banknote_authentication ...\n",
      "********************\n",
      "Reading pipelines for LL0_32_pendigits ...\n",
      "********************\n",
      "Reading pipelines for LL0_296_ailerons ...\n",
      "********************\n",
      "Reading pipelines for LL0_1476_gas_drift ...\n",
      "********************\n",
      "Reading pipelines for LL0_179_adult ...\n",
      "********************\n",
      "Reading pipelines for LL0_1557_abalone ...\n",
      "********************\n",
      "Reading pipelines for LL0_337_spectf ...\n",
      "********************\n",
      "Reading pipelines for LL0_40650_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001 ...\n",
      "********************\n",
      "Reading pipelines for LL0_40478_thyroid_dis ...\n",
      "********************\n",
      "Reading pipelines for LL0_557_analcatdata_apnea1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_40702_flare ...\n",
      "********************\n",
      "Reading pipelines for LL0_30_page_blocks ...\n",
      "********************\n",
      "Reading pipelines for LL0_1_anneal ...\n",
      "********************\n",
      "Reading pipelines for LL0_1026_grub_damage ...\n",
      "********************\n",
      "Reading pipelines for LL0_1547_autouniv_au1_1000 ...\n",
      "********************\n",
      "Reading pipelines for LL0_21_car ...\n",
      "********************\n",
      "Reading pipelines for LL0_40693_xd6 ...\n",
      "********************\n",
      "Reading pipelines for LL0_40708_allrep ...\n",
      "********************\n",
      "Reading pipelines for LL0_287_wine_quality ...\n",
      "********************\n",
      "Reading pipelines for LL0_454_analcatdata_halloffame ...\n",
      "********************\n",
      "Reading pipelines for LL0_16_mfeat_karhunen ...\n",
      "********************\n",
      "Reading pipelines for LL0_40498_wine_quality_white ...\n",
      "********************\n",
      "Reading pipelines for LL0_49_heart_c ...\n",
      "********************\n",
      "Reading pipelines for LL0_562_cpu_small ...\n",
      "********************\n",
      "Reading pipelines for LL0_851_tecator ...\n",
      "********************\n",
      "Reading pipelines for LL0_572_bank8fm ...\n",
      "********************\n",
      "Reading pipelines for LL0_207_autoPrice ...\n",
      "********************\n",
      "Reading pipelines for LL0_40682_thyroid_new ...\n",
      "********************\n",
      "Reading pipelines for LL0_1443_pizzacutter1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_227_cpu_small ...\n",
      "********************\n",
      "Reading pipelines for LL0_567_kdd_coil_1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_529_pollen ...\n",
      "********************\n",
      "Reading pipelines for LL0_482_arsenic_male_bladder ...\n",
      "********************\n",
      "Reading pipelines for LL0_451_irish ...\n",
      "********************\n",
      "Reading pipelines for LL0_446_prnn_crabs ...\n",
      "********************\n",
      "Reading pipelines for LL0_519_vinnie ...\n",
      "********************\n",
      "Reading pipelines for LL0_uci_las_vegas_strip ...\n",
      "********************\n",
      "Reading pipelines for LL0_1496_ringnorm ...\n",
      "********************\n",
      "Reading pipelines for LL0_688_visualizing_soil ...\n",
      "********************\n",
      "Reading pipelines for LL0_375_japanesevowels ...\n",
      "********************\n",
      "Reading pipelines for LL0_54_vehicle ...\n",
      "********************\n",
      "Reading pipelines for LL0_1520_robot_failures_lp5 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1485_madelon ...\n",
      "********************\n",
      "Reading pipelines for LL0_1435_fourclass ...\n",
      "********************\n",
      "Reading pipelines for LL0_1046_mozilla4 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1464_blood_transfusion_service_center ...\n",
      "********************\n",
      "Reading pipelines for LL0_1122_ap_breast_prostate ...\n",
      "********************\n",
      "Reading pipelines for LL0_225_puma8nh ...\n",
      "********************\n",
      "Reading pipelines for LL0_690_visualizing_galaxy ...\n",
      "********************\n",
      "Reading pipelines for LL0_547_no2 ...\n",
      "********************\n",
      "Reading pipelines for LL0_939_chscase_whale ...\n",
      "********************\n",
      "Reading pipelines for LL0_uci_facebook_metrics ...\n",
      "********************\n",
      "Reading pipelines for LL0_1505_tamilnadu_electricity ...\n",
      "********************\n",
      "Reading pipelines for LL0_1065_kc3 ...\n",
      "********************\n",
      "Reading pipelines for LL0_15_breast_w ...\n",
      "********************\n",
      "Reading pipelines for LL0_1554_autouniv_au7_500 ...\n",
      "********************\n",
      "Reading pipelines for LL0_35_dermatology ...\n",
      "********************\n",
      "Reading pipelines for LL0_294_satellite_image ...\n",
      "********************\n",
      "Reading pipelines for LL0_14_mfeat_fourier ...\n",
      "********************\n",
      "Reading pipelines for LL0_478_collins ...\n",
      "********************\n",
      "Reading pipelines for LL0_1071_mw1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_520_analcatdata_wildcat ...\n",
      "********************\n",
      "Reading pipelines for LL0_1523_vertebra_column ...\n",
      "********************\n",
      "Reading pipelines for LL0_228_breast_cancer_wisconsin_diagnostic ...\n",
      "********************\n",
      "Reading pipelines for LL0_947_arsenic_male_bladder ...\n",
      "********************\n",
      "Reading pipelines for LL0_1449_MeanWhile1 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1515_micro_mass ...\n",
      "********************\n",
      "Reading pipelines for LL0_1217_click_prediction_small ...\n",
      "********************\n",
      "Reading pipelines for LL0_1589_svmguide3 ...\n",
      "********************\n",
      "Reading pipelines for LL0_1549_autouniv_au6_750 ...\n",
      "********************\n",
      "Reading pipelines for LL0_335_monks_problems_3 ...\n",
      "********************\n",
      "Reading pipelines for LL0_29_credit_approval ...\n",
      "********************\n",
      "Reading pipelines for LL0_464_prnn_synth ...\n",
      "********************\n",
      "Reading pipelines for LL0_4153_Smartphone_Based_Recognition_of_Human_Activities ...\n",
      "********************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce3075e443e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_pipelines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_fitted_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-27c9e76fa40d>\u001b[0m in \u001b[0;36mload_all_fitted_pipeline\u001b[0;34m(pipeline_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mpip_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_for_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# print(allfile)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-27c9e76fa40d>\u001b[0m in \u001b[0;36mload_for_dataset\u001b[0;34m(path, res)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipelines_for_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtmp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_one_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-27c9e76fa40d>\u001b[0m in \u001b[0;36mload_one_pipeline\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pipeline_rank\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs1/dsbox-repo/qasemi/miniconda/envs/d3m-devel/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m--> 296\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs1/dsbox-repo/qasemi/miniconda/envs/d3m-devel/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_pipelines = load_all_fitted_pipeline(runs_loc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # print(args.path, args.filename)\n",
    "    all_pipelines = load_all_fitted_pipeline(args.path)\n",
    "    run_pipelines = top_selection(all_pipelines)\n",
    "\n",
    "    for dataset_pipeline in run_pipelines.keys():\n",
    "        print(\"Start testing\", dataset_pipeline)\n",
    "        folder_path = os.path.join(args.path, dataset_pipeline)\n",
    "        dataset, problem = load_test_dataset_for_pipeline(os.path.join(args.configs, dataset_pipeline))\n",
    "        print(\"Using dataset\", dataset, \"and problem description\", problem)\n",
    "        fitted_pipelines = create_fitted_pipelines_for_dataset(folder_path, run_pipelines[dataset_pipeline], os.path.join(folder_path, \"logs\"))\n",
    "        for fitted_pipeline, run in fitted_pipelines:\n",
    "            '''\n",
    "            sequence associate with rank\n",
    "            '''\n",
    "            # print(fitted_pipelines)\n",
    "            fname = fitted_pipeline.id + \".csv\"\n",
    "            dir_path = os.path.join(folder_path, \"results\")\n",
    "            # if not os.path.exists(dir_path):\n",
    "            #     try:\n",
    "            #         os.makedirs(os.path.dirname(dir_path))\n",
    "            #     except:\n",
    "            #         print(\"path not created.\")\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            saving_path = os.path.join(dir_path, fname)\n",
    "            prediction_file = predict_and_write(fitted_pipeline, dataset, problem, saving_path)\n",
    "            # score_prediction(prediction_file)\n",
    "            # fitted_pipeline.produce(inputs =[dataset])\n",
    "            # prediction = fitted_pipeline.produce_outputs[-1]\n",
    "    # print(run_pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Test all fitted pipeline and give results\")\n",
    "    parser.add_argument(\"--path\", help=\"Where the pipelines stored, example: /nfs1/dsbox-repo/muxin/ta2-outputs/seed\", default=\"/nfs1/dsbox-repo/muxin/ta2-outputs/seed\")\n",
    "    parser.add_argument(\"--configs\", help=\"Where the configuration files stored, example: /nfs1/dsbox-repo/muxin/all_confs/seed\", default=\"/nfs1/dsbox-repo/muxin/all_confs/seed\")\n",
    "    parser.add_argument(\"--filename\", help=\"Name of the output csv\", default=-1)\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
