#!/usr/bin/env python

"""
Command Line Interface for running the DSBox TA2 Search
"""
import time
import argparse
import json
import os
import signal
import sys
import traceback
import psutil

from pprint import pprint
from dsbox.controller.controller import Controller
from dsbox.controller.config import DsboxConfig

# controller = Controller(development_mode=True)

start_time = time.time()


def main(args):
    timeout = 0
    configuration_file = args.configuration_file
    debug = args.debug

    controller = Controller(development_mode=debug)

    config = DsboxConfig()
    config.load(configuration_file)

    # Time to write results (in minutes)
    write_results_time = 2
    if args.timeout > write_results_time:
        timeout = args.timeout - write_results_time
    else:
        if 'timeout' in config:
            # Timeout less 1 minute to give system chance to clean up
            timeout = int(config['timeout']) - write_results_time
        else:
            timeout = 60 - write_results_time
    config['timeout'] = timeout

    print('[INFO] Time out is ', timeout)

    def kill_child_processes():
        process_id = os.getpid()
        parent = psutil.Process(process_id)
        for child in parent.children(recursive=True):  # or parent.children() for recursive=False
            child.kill()

    # Define signal handler to exit gracefully
    def write_results_and_exit(a_signal, frame):
        print('==== Times up ====')
        time_used = (time.time() - start_time) / 60.0
        print("[INFO] The time used so far is {:0.2f} minutes.".format(time_used))
        try:
            # Reset to handlers to default as not to output multiple times
            signal.signal(signal.SIGALRM, signal.SIG_DFL)

            print('[INFO] Killing child processes', flush=True)

            print('[INFO] writing results', flush=True)
            controller.write_training_results()

            print('==== Done cleaning up ====', flush=True)
            time_used = (time.time() - start_time) / 60.0
            print("[INFO] The time used so far is {:0.2f} minutes.".format(time_used), flush=True)

            kill_child_processes()
        except Exception as e:
            print(e)
            traceback.print_exc()
        finally:
            # sys.exit(0) generates SystemExit exception, which may
            # be caught and ignored.

            # This os._exit() cannot be caught.
            # print('SIGNAL exiting {}'.format(configuration_file), flush=True)
            best_pipeline_id = None
            if args.test:
                best_pipeline_id = run_single_test()

            if args.test_generated_pipelines:
                run_generated_pipelines(best_pipeline_id)

            kill_child_processes()
            os._exit(0)

    def run_single_test():
        print("[INFO] Pick the best pipeline and run a test")
        test_config_single_pipeline = json.load(open(args.test, 'r'))
        test_controller_single_pipeline = Controller(development_mode=False)
        test_controller_single_pipeline.initialize_from_config_for_evaluation(test_config_single_pipeline)

        rank_lst = list()
        for pipeline in [os.path.join(controller.output_pipelines_dir, x) for x in
                         os.listdir(controller.output_pipelines_dir) if x.endswith(".json")]:
            pipeline_json = json.load(open(pipeline, 'r'))
            rank_lst.append((pipeline_json["pipeline_rank"], pipeline_json['id']))
        best_fitted_pipeline_id = min(rank_lst)[1]
        test_controller_single_pipeline.test_fitted_pipeline(fitted_pipeline_id=best_fitted_pipeline_id)
        return best_fitted_pipeline_id

    def run_generated_pipelines(best_pipeline_id=None):
        print("[INFO] Pick all pipelines and run test")
        test_config = json.load(open(args.test_generated_pipelines, 'r'))
        test_controller = Controller(development_mode=False)
        test_controller.initialize_from_config_for_evaluation(test_config)

        for pipeline in [os.path.join(controller.output_pipelines_dir, x) for x in
                         os.listdir(controller.output_pipelines_dir) if x.endswith(".json")]:
            pipeline_json = json.load(open(pipeline, 'r'))
            fitted_pipeline_id = pipeline_json['id']
            if fitted_pipeline_id != best_pipeline_id:
                test_controller.test_fitted_pipeline(fitted_pipeline_id=fitted_pipeline_id)

    if timeout > 0:
        signal.signal(signal.SIGALRM, write_results_and_exit)
        signal.alarm(60 * timeout)
    else:
        # Do not set alaram
        pass

    if args.cpus > -1:
        config['cpus'] = args.cpus

    # Replace output directories
    if args.output_prefix is not None:
        config.map_output_variables(args.output_prefix)

    # os.system('clear')
    print('Using configuation:')
    pprint(config)

    controller.initialize_from_config_train_test(config)

    status = controller.train()
    print("*+" * 10)
    controller.write_training_results()
    print("*+" * 10)
    # status = controller.test()
    # print("[INFO] Testing Done")
    if args.test:
        best_pipeline_id = run_single_test()

    if args.test_generated_pipelines:
        run_generated_pipelines(best_pipeline_id)

    time_used = (time.time() - start_time) / 60.0
    print("[INFO] The time used for running program is {:0.2f} minutes.".format(time_used))

    return status.value


class StdoutLogger(object):
    def __init__(self, f):
        self.terminal = sys.stdout
        self.log = f

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.log.flush()


class StderrLogger(object):
    def __init__(self, f):
        self.err = sys.stderr
        self.log = f

    def write(self, message):
        self.err.write(message)
        self.log.write(message)

    def flush(self):
        self.log.flush()


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Run DSBox TA2 system using json configuration file')

    parser.add_argument('configuration_file',
                        help='D3M TA2 json configuration file')
    parser.add_argument('--timeout', action='store', type=int, default=-1,
                        help='Overide configuation timeout setting. In minutes.')
    parser.add_argument('--cpus', action='store', type=int, default=-1,
                        help='Overide configuation number of cpus usage setting')
    parser.add_argument('--output-prefix', action='store', default=None,
                        help='''Overide configuation output directories paths (
                        pipeline_logs_root, executables_root, temp_storage_root).
                        Replace path prefix "*/output/" with argument''')
    parser.add_argument('--debug', action='store_true', default=False,
                        help='Debug mode. No timeout and no output redirection')

    parser.add_argument('--test', action='store', default=None,
                        help='Run a single test after search, need a test config')

    parser.add_argument('--test_generated_pipelines', action='store', default=None,
                        help='After search, run all generated pipelines on test data, need a test config')

    args = parser.parse_args()

    config = json.load(open(args.configuration_file, "r"))
    if 'logs_root' in config:
        std_dir = os.path.abspath(config['logs_root'])
    else:
        std_dir = os.path.join(config['temp_storage_root'], 'logs')

    os.makedirs(std_dir, exist_ok=True)

    orig_stdout = sys.stdout
    orig_stderr = sys.stderr
    f = open(os.path.join(std_dir, 'out.txt'), 'w')

    sys.stdout = StdoutLogger(f)
    sys.stderr = StderrLogger(f)

    print(args)

    result = main(args)
    sys.stdout = orig_stdout
    sys.stderr = orig_stderr

    f.close()

    os._exit(result)
